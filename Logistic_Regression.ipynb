{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Logistic Regression** in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 27)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole dataset:  (887, 6) (887,)\n",
      "training set:  (665, 6) (665,)\n",
      "test set:  (222, 6) (222,)\n"
     ]
    }
   ],
   "source": [
    "print('whole dataset: ', X.shape, y.shape)\n",
    "print('training set: ', X_train.shape, y_train.shape)\n",
    "print('test set: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Logistic Regression Threshold:** <br/>\n",
    "We can choose any threshold between 0 and 1. <br/>\n",
    "If we make the threshold higher, we'll have fewer positive predictions, but our predictions are more likely to be correct. This means that the **precision** would be higher and the recall lower. On the other hand, if we make the threshold lower, we'll have more positive predictions, so we're more likely to catch all the positive cases. This means that the recall would be higher and the precision lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7882882882882883\n",
      "precision:  0.7368421052631579\n",
      "recall:  0.6746987951807228\n",
      "f1 score:  0.7044025157232704\n",
      "confusion_matrix:  [[119  20]\n",
      " [ 27  56]]\n",
      "sensitivity score:  0.6746987951807228\n",
      "precision_recall_fscore_support:  (array([0.81506849, 0.73684211]), array([0.85611511, 0.6746988 ]), array([0.83508772, 0.70440252]), array([139,  83]))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred))\n",
    "print('recall: ', recall_score(y_test, y_pred))\n",
    "print('f1 score: ', f1_score(y_test, y_pred))\n",
    "print('confusion_matrix: ', confusion_matrix(y_test, y_pred)) \n",
    "# row1: Actual Negative, column1: Predicted Negative\n",
    "# row2: Actual Positive, column2: Predicted Positive\n",
    "sensitivity_score = recall_score\n",
    "print('sensitivity score: ', sensitivity_score(y_test, y_pred))\n",
    "print('precision_recall_fscore_support: ', precision_recall_fscore_support(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity_score:  0.8561151079136691\n"
     ]
    }
   ],
   "source": [
    "def specificity_score(y_true, y_pred):\n",
    "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return r[0]\n",
    "\n",
    "print('specificity_score: ',specificity_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict proba\n",
      "[[0.53171991 0.46828009]\n",
      " [0.31779192 0.68220808]\n",
      " [0.48898444 0.51101556]\n",
      " [0.53143654 0.46856346]\n",
      " [0.24206161 0.75793839]]\n"
     ]
    }
   ],
   "source": [
    "print('predict proba')\n",
    "print(model.predict_proba(X_test)[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.9714285714285714\n",
      "recall:  0.40963855421686746\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_test)[:, 1] > 0.75 # threshold 0.75\n",
    "print('precision: ', precision_score(y_test, y_pred))\n",
    "print('recall: ', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
